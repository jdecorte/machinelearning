{"cells":[{"cell_type":"markdown","metadata":{"id":"4iZhTJCu900D"},"source":["# E-mail classification\n","Service departments are often providing a central e-mailadres to their (internal or external) customers for reporting issues. Often, different topics are handled by different people or departments. Wouldn’t it be great to have an automatic e-mail classifier that forwards e-mails to the right person? Let’s try to make this.  \n","  \n","We start from a set of 9.820 real e-mails originating from several e-mail services like monster.com, nieuwsblad.be, datanews.be, etc.. The e-mails belong to four categories: _advertisements_ , _job offerings_ , _news_ and _ICT_ . We’d like to create a classifier that can be used to automatically classify e-mails into one of the four categories ADS, JOB, NEWS and ICT. \n","We start by importing and exploring the data. \n","\n","In a previous exercise we used word embeddings and a neural network for document classification, but do we really need these advanced and compute-intensive techniques?\n","\n","Create a model based on based on TFidVectorizer iso word embeddings and use a voting classifier.   \n","\n","Compare the accuracy of this model to the accuracy of the neural network you created above. \n"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7405,"status":"ok","timestamp":1652414651267,"user":{"displayName":"Sabine De Vreese","userId":"01431929970271618335"},"user_tz":-120},"id":"hik9nDQtAFrc","outputId":"f7341a8f-a3f4-474f-faea-35d785923299"},"outputs":[],"source":["# Importing the necessary packages\n","import numpy as np                                  # \"Scientific computing\"\n","import scipy.stats as stats                         # Statistical tests\n","\n","import pandas as pd                                 # Data Frame\n","from pandas.api.types import CategoricalDtype\n","\n","import matplotlib.pyplot as plt                     # Basic visualisation\n","\n","import seaborn as sns                               # Advanced data visualisation\n","\n","from sklearn.model_selection import cross_val_score\n","from sklearn.compose import ColumnTransformer\n","from sklearn.pipeline import Pipeline\n","from sklearn.preprocessing import MinMaxScaler\n","\n","# Helper libraries\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import sklearn as sk\n","import pandas as pd\n","\n","# fix random seed for reproducibility\n","seed = 2020\n","np.random.seed(seed)  \n","\n","import sklearn as sk\n","from sklearn.model_selection import train_test_split\n","\n","\n","import nltk\n"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20819,"status":"ok","timestamp":1652414672074,"user":{"displayName":"Sabine De Vreese","userId":"01431929970271618335"},"user_tz":-120},"id":"SAUWwKSaAI0q","outputId":"14236d85-103a-4cc6-8e31-64be571d5442"},"outputs":[{"name":"stdout","output_type":"stream","text":["You are not running on Google Colab\n"]}],"source":["if 'google.colab' in str(get_ipython()):\n","    colab = True\n","    print ('You are running on Google Colab')\n","else:\n","    colab = False\n","    print ('You are not running on Google Colab')\n","\n","if colab:\n","    from google.colab import drive\n","    drive.mount('/content/gdrive')"]},{"cell_type":"markdown","metadata":{"id":"hNaYwydBo-n3"},"source":["Read the files"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":5958,"status":"ok","timestamp":1652414678026,"user":{"displayName":"Sabine De Vreese","userId":"01431929970271618335"},"user_tz":-120},"id":"xTO2vRFi900I"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","\n","if colab:\n","    ads = pd.read_csv('https://raw.githubusercontent.com/jdecorte/machinelearning/main/datasets/emailADS.csv',encoding = \"ISO-8859-1\")\n","    ict = pd.read_csv('https://raw.githubusercontent.com/jdecorte/machinelearning/main/datasets/emailICT.csv',encoding = \"ISO-8859-1\")\n","    job = pd.read_csv('https://raw.githubusercontent.com/jdecorte/machinelearning/main/datasets/emailJOB.csv',encoding = \"ISO-8859-1\")\n","    news = pd.read_csv('https://raw.githubusercontent.com/jdecorte/machinelearning/main/datasets/emailNEWS.csv',encoding = \"ISO-8859-1\")\n","else:\n","    ads = pd.read_csv('datasets/emailADS.csv',encoding = \"ISO-8859-1\")\n","    ict = pd.read_csv('datasets/emailICT.csv',encoding = \"ISO-8859-1\")\n","    job = pd.read_csv('datasets/emailJOB.csv',encoding = \"ISO-8859-1\")\n","    news = pd.read_csv('datasets/emailNEWS.csv',encoding = \"ISO-8859-1\")\n","\n"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["C:\\Users\\jcor864\\AppData\\Local\\Temp\\ipykernel_16528\\3339414562.py:1: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  data = ads.append([ict,job,news])\n"]}],"source":["data = ads.append([ict,job,news])"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Category</th>\n","      <th>Text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>ADS</td>\n","      <td>Alles halve prijs - of nog veel goedkoper!  &lt;h...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>ADS</td>\n","      <td>Alles halve prijs - of nog veel goedkoper!  &lt;h...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>ADS</td>\n","      <td>Wat krijgen we nu?! Weer EXTRA korting?  &lt;http...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>ADS</td>\n","      <td>Wat krijgen we nu?! Weer EXTRA korting?  &lt;http...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>ADS</td>\n","      <td>Armband met activiteitstracker, Apple iPhone 6...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  Category                                               Text\n","0      ADS  Alles halve prijs - of nog veel goedkoper!  <h...\n","1      ADS  Alles halve prijs - of nog veel goedkoper!  <h...\n","2      ADS  Wat krijgen we nu?! Weer EXTRA korting?  <http...\n","3      ADS  Wat krijgen we nu?! Weer EXTRA korting?  <http...\n","4      ADS  Armband met activiteitstracker, Apple iPhone 6..."]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["data = data[['Subject','Body','Category']]  # we only keep these three columns \n","data['Text'] = data['Subject'] + ' ' + data['Body']\n","data = data.drop(['Subject','Body'],axis=1)\n","data.head()"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["# language detection - this can take a while\n","from langdetect import detect\n","data['Lang'] = data['Text'].apply(detect)"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th>Lang</th>\n","      <th>ca</th>\n","      <th>de</th>\n","      <th>en</th>\n","      <th>fr</th>\n","      <th>nl</th>\n","    </tr>\n","    <tr>\n","      <th>Category</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>ADS</th>\n","      <td>61.0</td>\n","      <td>112.0</td>\n","      <td>751.0</td>\n","      <td>2.0</td>\n","      <td>1558.0</td>\n","    </tr>\n","    <tr>\n","      <th>ICT</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1140.0</td>\n","      <td>0.0</td>\n","      <td>223.0</td>\n","    </tr>\n","    <tr>\n","      <th>JOB</th>\n","      <td>0.0</td>\n","      <td>6.0</td>\n","      <td>960.0</td>\n","      <td>5.0</td>\n","      <td>611.0</td>\n","    </tr>\n","    <tr>\n","      <th>NEWS</th>\n","      <td>0.0</td>\n","      <td>8.0</td>\n","      <td>8.0</td>\n","      <td>0.0</td>\n","      <td>4375.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["Lang        ca     de      en   fr      nl\n","Category                                  \n","ADS       61.0  112.0   751.0  2.0  1558.0\n","ICT        0.0    0.0  1140.0  0.0   223.0\n","JOB        0.0    6.0   960.0  5.0   611.0\n","NEWS       0.0    8.0     8.0  0.0  4375.0"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["pd.pivot_table(data, values='Text', index=['Category'],columns=['Lang'], aggfunc='count').fillna(0)"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Category</th>\n","      <th>Text</th>\n","      <th>Lang</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>ADS</td>\n","      <td>Alles halve prijs - of nog veel goedkoper!  &lt;h...</td>\n","      <td>nl</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>ADS</td>\n","      <td>Alles halve prijs - of nog veel goedkoper!  &lt;h...</td>\n","      <td>nl</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>ADS</td>\n","      <td>Wat krijgen we nu?! Weer EXTRA korting?  &lt;http...</td>\n","      <td>nl</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>ADS</td>\n","      <td>Wat krijgen we nu?! Weer EXTRA korting?  &lt;http...</td>\n","      <td>nl</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>ADS</td>\n","      <td>Armband met activiteitstracker, Apple iPhone 6...</td>\n","      <td>nl</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  Category                                               Text Lang\n","0      ADS  Alles halve prijs - of nog veel goedkoper!  <h...   nl\n","1      ADS  Alles halve prijs - of nog veel goedkoper!  <h...   nl\n","2      ADS  Wat krijgen we nu?! Weer EXTRA korting?  <http...   nl\n","3      ADS  Wat krijgen we nu?! Weer EXTRA korting?  <http...   nl\n","4      ADS  Armband met activiteitstracker, Apple iPhone 6...   nl"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["# Using the mails in dutch and english gives a better result (see Exploration 3)\n","data = data[(data['Lang'] == \"nl\") | (data['Lang'] == \"en\")]\n","data.head()"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package stopwords to\n","[nltk_data]     C:\\Users\\jcor864\\AppData\\Roaming\\nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n"]}],"source":["# remove stopwords and punctuations\n","import nltk\n","nltk.download('stopwords')\n","# nltk.download('punkt')\n","\n","from nltk.corpus import stopwords \n","from nltk.tokenize import word_tokenize \n","import string\n","    \n","stop_words_nl = set(stopwords.words('dutch')) \n","\n","from nltk.stem.snowball import SnowballStemmer\n","\n","dutchStemmer=SnowballStemmer(\"dutch\")\n","\n","punctuations=\"?:!.,;<>/\\+-\"\n","\n","# define functions to remove digits stopwords from a string\n","# I know we are copy-pasting code, but this is for now the simpliest way\n","\n","def remove_stopwords_nl(s):\n","    word_tokens = word_tokenize(s.lower()) # turn the string into a list of words based on separators (blank, comma, etc.)\n","    filtered_sentence = \"\"\n","    result = [dutchStemmer.stem(x) for x in word_tokens if x not in stop_words_nl and x not in punctuations]\n","    seperator = ' '\n","    return seperator.join(result)\n","\n","data['Text'] = data['Text'].apply(remove_stopwords_nl)"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["import re\n","\n","def clean_pieces_urls(piece):\n","  return re.sub(r\"[,.;@#?!&$/=]+\\ *\", \" \", piece)\n","\n","data['Text'] = data['Text'].apply(clean_pieces_urls)"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"data":{"text/plain":["NEWS    4383\n","ADS     2309\n","JOB     1571\n","ICT     1363\n","Name: Category, dtype: int64"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["data.Category.value_counts()"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["dict_map = {'NEWS': 0, 'ADS': 1, 'JOB': 2, 'ICT': 3}\n","data['Category'] = data['Category'].map(dict_map)"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[],"source":["# Extract a training & validation split\n","from sklearn.model_selection import train_test_split\n","X = data['Text']\n","y = data['Category']\n","X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.20, random_state=42)"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Shape of x_train: (7700,)\n","Shape of x_test: (1926,)\n","Shape of y_train: (7700,)\n","Shape of y_test: (1926,)\n"]}],"source":["print(\"Shape of x_train:\", X_train.shape)\n","print(\"Shape of x_test:\", X_test.shape)\n","\n","print(\"Shape of y_train:\", y_train.shape)\n","print(\"Shape of y_test:\", y_test.shape)\n"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[],"source":["from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.svm import SVC\n","from sklearn.ensemble import VotingClassifier\n","\n","log_clf = LogisticRegression(solver='lbfgs',random_state=42)\n","rnd_clf = RandomForestClassifier(n_estimators=100,random_state=42)\n","svm_clf = SVC(gamma='scale',random_state=42)\n","\n","voting_clf = VotingClassifier(\n","    estimators=[('lr',log_clf),('rf',rnd_clf),('svc',svm_clf)]\n",")\n","\n","model = Pipeline([('tfid',TfidfVectorizer()),('voting',voting_clf)])\n","\n","model.fit(X_train,y_train)\n","categories = model.predict(X_test)"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["0.9984423676012462\n"]}],"source":["from sklearn.metrics import accuracy_score\n","\n","print(accuracy_score(y_test,categories))"]}],"metadata":{"celltoolbar":"Slideshow","colab":{"collapsed_sections":[],"name":"email_classification Solution.ipynb","provenance":[]},"interpreter":{"hash":"11938c6bc6919ae2720b4d5011047913343b08a43b18698fd82dedb0d4417594"},"kernelspec":{"display_name":"Python 3.9.12 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.12"}},"nbformat":4,"nbformat_minor":0}
